<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>1 on Rui Zhu</title>
    <link>https://jerrypiglet.github.io/publication_types/1/</link>
    <description>Recent content in 1 on Rui Zhu</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>&amp;copy; 2017 Rui Zhu</copyright>
    <lastBuildDate>Tue, 11 Oct 2016 00:00:00 +0000</lastBuildDate>
    <atom:link href="/publication_types/1/" rel="self" type="application/rss+xml" />
    
    <item>
      <title>The Conditional Lucas &amp; Kanade Algorithm</title>
      <link>https://jerrypiglet.github.io/publication/condlk/</link>
      <pubDate>Tue, 11 Oct 2016 00:00:00 +0000</pubDate>
      
      <guid>https://jerrypiglet.github.io/publication/condlk/</guid>
      <description>&lt;p&gt;The Lucas &amp;amp; Kanade (LK) algorithm is the method of choice for efficient dense image and object alignment. The approach is efficient as it attempts to model the connection between appearance and geometric displacement through a linear relationship that assumes independence across pixel coordinates. A drawback of the approach, however, is its generative nature. Specifically, its performance is tightly coupled with how well the linear model can synthesize appearance from geometric displacement, even though the alignment task itself is associated with the inverse problem. In this paper, we present a new approach, referred to as the Conditional LK algorithm, which: (i) directly learns linear models that predict geometric displacement as a function of appearance, and (ii) employs a novel strategy for ensuring that the generative pixel independence assumption can still be taken advantage of. We demonstrate that our approach exhibits superior performance to classical generative forms of the LK algorithm. Furthermore, we demonstrate its comparable performance to state-of-the-art methods such as the Supervised Descent Method with substantially less training examples, as well as the unique ability to &amp;ldquo;swap&amp;rdquo; geometric warp functions without having to retrain from scratch. Finally, from a theoretical perspective, our approach hints at possible redundancies that exist in current state-of-the-art methods for alignment that could be leveraged in vision systems of the future.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
